{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab5102d-8ab8-4fe8-b0cb-847d14f7a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ef33d6-7b06-453f-a3f2-eaf7f3b4cd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")\n",
    "dataset\n",
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67642532-cfad-4ab6-bc86-4e9697b35c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b5a889-629d-4d7a-9640-35e444de1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataset[['R&D Spend', 'Administration', 'Marketing Spend','State_Florida', 'State_New York']]\n",
    "dependent = dataset[['Profit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82731406-30d2-4689-add3-6f7bc4b38ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Set Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(independent,dependent,test_size =0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91b9a9f-d33d-4c1d-9e32-e703f46221f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data preprocessing standarsdization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "# x_train  # pre processed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872281c0-5824-4fda-8d8c-98c23ecdde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                       'absolute_error', 'poisson'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridserarch - training case data - model creation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {'criterion':['squared_error','friedman_mse','absolute_error','poisson'],'max_features': ['sqrt','log2'],'n_estimators':[50,100]}\n",
    "grid = GridSearchCV(RandomForestRegressor(),param_grid,refit=True,verbose = 3,n_jobs=-1)\n",
    "grid.fit(x_train,y_train)  # in this \"fit\" model creating - values substituion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e4c3b7-b028-449a-9b0d-151a99a70e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08594837, 0.14861321, 0.0764564 , 0.15073304, 0.07926888,\n",
       "        0.15042882, 0.0742197 , 0.14668479, 0.08248358, 0.1618845 ,\n",
       "        0.08021917, 0.16283731, 0.07789707, 0.14850383, 0.07625284,\n",
       "        0.11377339]),\n",
       " 'std_fit_time': array([0.01117828, 0.00636029, 0.00373773, 0.00148112, 0.00612587,\n",
       "        0.00436071, 0.00381025, 0.00335284, 0.00395629, 0.00430821,\n",
       "        0.00038465, 0.00232203, 0.00381938, 0.00226745, 0.00365696,\n",
       "        0.01139201]),\n",
       " 'mean_score_time': array([0.00361772, 0.00946612, 0.00424194, 0.00600677, 0.0036119 ,\n",
       "        0.00817766, 0.00722694, 0.01004558, 0.0052392 , 0.0075047 ,\n",
       "        0.00463314, 0.00980701, 0.00401273, 0.01112213, 0.00646887,\n",
       "        0.0057261 ]),\n",
       " 'std_score_time': array([0.00367778, 0.00497452, 0.0036013 , 0.00218241, 0.00321723,\n",
       "        0.00319276, 0.00372455, 0.00073129, 0.00433826, 0.00193707,\n",
       "        0.0041113 , 0.00108485, 0.00420669, 0.00226943, 0.00197922,\n",
       "        0.00395199]),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'absolute_error',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'poisson', 'poisson', 'poisson', 'poisson'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
       "                    50, 100, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'squared_error',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.92477157, 0.89936725, 0.92205528, 0.89338907, 0.86921068,\n",
       "        0.90177287, 0.89055049, 0.90247035, 0.89787405, 0.87408088,\n",
       "        0.85295327, 0.91915651, 0.91816488, 0.91780764, 0.90749749,\n",
       "        0.91610043]),\n",
       " 'split1_test_score': array([0.91109637, 0.83830959, 0.77993342, 0.86117921, 0.82797275,\n",
       "        0.91129738, 0.80740559, 0.8790366 , 0.81341601, 0.87431038,\n",
       "        0.79025449, 0.86600688, 0.86643771, 0.85794581, 0.86887957,\n",
       "        0.88413976]),\n",
       " 'split2_test_score': array([0.84278637, 0.81911108, 0.86580724, 0.8382259 , 0.83439994,\n",
       "        0.85038657, 0.81115497, 0.84699329, 0.82726261, 0.83682266,\n",
       "        0.87165877, 0.8302984 , 0.83980901, 0.81864581, 0.80935495,\n",
       "        0.82453172]),\n",
       " 'split3_test_score': array([0.53008232, 0.37888193, 0.50662954, 0.49607783, 0.37220988,\n",
       "        0.48616197, 0.40899652, 0.51088916, 0.45662043, 0.42122759,\n",
       "        0.3264672 , 0.42426065, 0.39795861, 0.40779261, 0.30670272,\n",
       "        0.2267094 ]),\n",
       " 'split4_test_score': array([0.78952706, 0.82694196, 0.79711664, 0.82849982, 0.80528933,\n",
       "        0.81652334, 0.81985385, 0.8074943 , 0.82732822, 0.82440154,\n",
       "        0.82124667, 0.82207698, 0.8470911 , 0.7971826 , 0.84434479,\n",
       "        0.84404533]),\n",
       " 'mean_test_score': array([0.79965274, 0.75252236, 0.77430842, 0.78347437, 0.74181652,\n",
       "        0.79322843, 0.74759228, 0.78937674, 0.76450026, 0.76616861,\n",
       "        0.73251608, 0.77235988, 0.77389226, 0.75987489, 0.7473559 ,\n",
       "        0.73910533]),\n",
       " 'std_test_score': array([0.14332177, 0.18894569, 0.14311185, 0.14542426, 0.1859364 ,\n",
       "        0.15736689, 0.17200216, 0.14285118, 0.15675316, 0.17361283,\n",
       "        0.20491381, 0.17738137, 0.18995181, 0.18075866, 0.2226384 ,\n",
       "        0.25815573]),\n",
       " 'rank_test_score': array([ 1, 11,  5,  4, 14,  2, 12,  3,  9,  8, 16,  7,  6, 10, 13, 15])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e804eb4d-44f9-4d22-aaf6-f0eb5e44a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085948</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.911096</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>0.530082</td>\n",
       "      <td>0.789527</td>\n",
       "      <td>0.799653</td>\n",
       "      <td>0.143322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148613</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.899367</td>\n",
       "      <td>0.838310</td>\n",
       "      <td>0.819111</td>\n",
       "      <td>0.378882</td>\n",
       "      <td>0.826942</td>\n",
       "      <td>0.752522</td>\n",
       "      <td>0.188946</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076456</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.922055</td>\n",
       "      <td>0.779933</td>\n",
       "      <td>0.865807</td>\n",
       "      <td>0.506630</td>\n",
       "      <td>0.797117</td>\n",
       "      <td>0.774308</td>\n",
       "      <td>0.143112</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150733</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.893389</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>0.838226</td>\n",
       "      <td>0.496078</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.783474</td>\n",
       "      <td>0.145424</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079269</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.869211</td>\n",
       "      <td>0.827973</td>\n",
       "      <td>0.834400</td>\n",
       "      <td>0.372210</td>\n",
       "      <td>0.805289</td>\n",
       "      <td>0.741817</td>\n",
       "      <td>0.185936</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.150429</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.901773</td>\n",
       "      <td>0.911297</td>\n",
       "      <td>0.850387</td>\n",
       "      <td>0.486162</td>\n",
       "      <td>0.816523</td>\n",
       "      <td>0.793228</td>\n",
       "      <td>0.157367</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074220</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.890550</td>\n",
       "      <td>0.807406</td>\n",
       "      <td>0.811155</td>\n",
       "      <td>0.408997</td>\n",
       "      <td>0.819854</td>\n",
       "      <td>0.747592</td>\n",
       "      <td>0.172002</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.146685</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.902470</td>\n",
       "      <td>0.879037</td>\n",
       "      <td>0.846993</td>\n",
       "      <td>0.510889</td>\n",
       "      <td>0.807494</td>\n",
       "      <td>0.789377</td>\n",
       "      <td>0.142851</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.082484</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.005239</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.897874</td>\n",
       "      <td>0.813416</td>\n",
       "      <td>0.827263</td>\n",
       "      <td>0.456620</td>\n",
       "      <td>0.827328</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.156753</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.161884</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.874081</td>\n",
       "      <td>0.874310</td>\n",
       "      <td>0.836823</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>0.824402</td>\n",
       "      <td>0.766169</td>\n",
       "      <td>0.173613</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.080219</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.852953</td>\n",
       "      <td>0.790254</td>\n",
       "      <td>0.871659</td>\n",
       "      <td>0.326467</td>\n",
       "      <td>0.821247</td>\n",
       "      <td>0.732516</td>\n",
       "      <td>0.204914</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.162837</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.919157</td>\n",
       "      <td>0.866007</td>\n",
       "      <td>0.830298</td>\n",
       "      <td>0.424261</td>\n",
       "      <td>0.822077</td>\n",
       "      <td>0.772360</td>\n",
       "      <td>0.177381</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.918165</td>\n",
       "      <td>0.866438</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.847091</td>\n",
       "      <td>0.773892</td>\n",
       "      <td>0.189952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.148504</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.857946</td>\n",
       "      <td>0.818646</td>\n",
       "      <td>0.407793</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.759875</td>\n",
       "      <td>0.180759</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.076253</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.907497</td>\n",
       "      <td>0.868880</td>\n",
       "      <td>0.809355</td>\n",
       "      <td>0.306703</td>\n",
       "      <td>0.844345</td>\n",
       "      <td>0.747356</td>\n",
       "      <td>0.222638</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>0.884140</td>\n",
       "      <td>0.824532</td>\n",
       "      <td>0.226709</td>\n",
       "      <td>0.844045</td>\n",
       "      <td>0.739105</td>\n",
       "      <td>0.258156</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.085948      0.011178         0.003618        0.003678   \n",
       "1        0.148613      0.006360         0.009466        0.004975   \n",
       "2        0.076456      0.003738         0.004242        0.003601   \n",
       "3        0.150733      0.001481         0.006007        0.002182   \n",
       "4        0.079269      0.006126         0.003612        0.003217   \n",
       "5        0.150429      0.004361         0.008178        0.003193   \n",
       "6        0.074220      0.003810         0.007227        0.003725   \n",
       "7        0.146685      0.003353         0.010046        0.000731   \n",
       "8        0.082484      0.003956         0.005239        0.004338   \n",
       "9        0.161884      0.004308         0.007505        0.001937   \n",
       "10       0.080219      0.000385         0.004633        0.004111   \n",
       "11       0.162837      0.002322         0.009807        0.001085   \n",
       "12       0.077897      0.003819         0.004013        0.004207   \n",
       "13       0.148504      0.002267         0.011122        0.002269   \n",
       "14       0.076253      0.003657         0.006469        0.001979   \n",
       "15       0.113773      0.011392         0.005726        0.003952   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0    squared_error               sqrt                 50   \n",
       "1    squared_error               sqrt                100   \n",
       "2    squared_error               log2                 50   \n",
       "3    squared_error               log2                100   \n",
       "4     friedman_mse               sqrt                 50   \n",
       "5     friedman_mse               sqrt                100   \n",
       "6     friedman_mse               log2                 50   \n",
       "7     friedman_mse               log2                100   \n",
       "8   absolute_error               sqrt                 50   \n",
       "9   absolute_error               sqrt                100   \n",
       "10  absolute_error               log2                 50   \n",
       "11  absolute_error               log2                100   \n",
       "12         poisson               sqrt                 50   \n",
       "13         poisson               sqrt                100   \n",
       "14         poisson               log2                 50   \n",
       "15         poisson               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_features':...           0.924772   \n",
       "1   {'criterion': 'squared_error', 'max_features':...           0.899367   \n",
       "2   {'criterion': 'squared_error', 'max_features':...           0.922055   \n",
       "3   {'criterion': 'squared_error', 'max_features':...           0.893389   \n",
       "4   {'criterion': 'friedman_mse', 'max_features': ...           0.869211   \n",
       "5   {'criterion': 'friedman_mse', 'max_features': ...           0.901773   \n",
       "6   {'criterion': 'friedman_mse', 'max_features': ...           0.890550   \n",
       "7   {'criterion': 'friedman_mse', 'max_features': ...           0.902470   \n",
       "8   {'criterion': 'absolute_error', 'max_features'...           0.897874   \n",
       "9   {'criterion': 'absolute_error', 'max_features'...           0.874081   \n",
       "10  {'criterion': 'absolute_error', 'max_features'...           0.852953   \n",
       "11  {'criterion': 'absolute_error', 'max_features'...           0.919157   \n",
       "12  {'criterion': 'poisson', 'max_features': 'sqrt...           0.918165   \n",
       "13  {'criterion': 'poisson', 'max_features': 'sqrt...           0.917808   \n",
       "14  {'criterion': 'poisson', 'max_features': 'log2...           0.907497   \n",
       "15  {'criterion': 'poisson', 'max_features': 'log2...           0.916100   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.911096           0.842786           0.530082   \n",
       "1            0.838310           0.819111           0.378882   \n",
       "2            0.779933           0.865807           0.506630   \n",
       "3            0.861179           0.838226           0.496078   \n",
       "4            0.827973           0.834400           0.372210   \n",
       "5            0.911297           0.850387           0.486162   \n",
       "6            0.807406           0.811155           0.408997   \n",
       "7            0.879037           0.846993           0.510889   \n",
       "8            0.813416           0.827263           0.456620   \n",
       "9            0.874310           0.836823           0.421228   \n",
       "10           0.790254           0.871659           0.326467   \n",
       "11           0.866007           0.830298           0.424261   \n",
       "12           0.866438           0.839809           0.397959   \n",
       "13           0.857946           0.818646           0.407793   \n",
       "14           0.868880           0.809355           0.306703   \n",
       "15           0.884140           0.824532           0.226709   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.789527         0.799653        0.143322                1  \n",
       "1            0.826942         0.752522        0.188946               11  \n",
       "2            0.797117         0.774308        0.143112                5  \n",
       "3            0.828500         0.783474        0.145424                4  \n",
       "4            0.805289         0.741817        0.185936               14  \n",
       "5            0.816523         0.793228        0.157367                2  \n",
       "6            0.819854         0.747592        0.172002               12  \n",
       "7            0.807494         0.789377        0.142851                3  \n",
       "8            0.827328         0.764500        0.156753                9  \n",
       "9            0.824402         0.766169        0.173613                8  \n",
       "10           0.821247         0.732516        0.204914               16  \n",
       "11           0.822077         0.772360        0.177381                7  \n",
       "12           0.847091         0.773892        0.189952                6  \n",
       "13           0.797183         0.759875        0.180759               10  \n",
       "14           0.844345         0.747356        0.222638               13  \n",
       "15           0.844045         0.739105        0.258156               15  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3966cc5f-fae4-4b10-99b2-e7407633a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction=grid.predict(x_test)\n",
    "#x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ee6e21-7bb3-4884-ae0a-203ec2d64b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7477584944575083"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(y_test,grid_prediction)\n",
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52be0f92-88f4-41e7-abe3-39de4400dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"finalized_model_RF.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37aa14b5-31e7-4dbf-8111-e82ccc14717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "705ddcd0-3539-4051-850b-ff8617fc02da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.49374843, -4.80327375, -1.53809178,  2.        ,  1.30088727]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput=sc.transform([[22,23.4,0,1,1]])\n",
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e0d4c7-9ef0-438b-8394-eb9f3de29b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_RF.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1a0b4a-cb77-4af3-99d4-37549b287cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49292.141])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77920710-fd68-46dd-b697-12a139700ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
