{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab5102d-8ab8-4fe8-b0cb-847d14f7a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ef33d6-7b06-453f-a3f2-eaf7f3b4cd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")\n",
    "dataset\n",
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67642532-cfad-4ab6-bc86-4e9697b35c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b5a889-629d-4d7a-9640-35e444de1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataset[['R&D Spend', 'Administration', 'Marketing Spend','State_Florida', 'State_New York']]\n",
    "dependent = dataset[['Profit']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82731406-30d2-4689-add3-6f7bc4b38ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Set Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(independent,dependent,test_size =0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91b9a9f-d33d-4c1d-9e32-e703f46221f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data preprocessing standarsdization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "# x_train  # pre processed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee55ffd-927f-475c-b62e-ab8457e9c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data preprocessing \n",
    "scy=StandardScaler()\n",
    "y_train=scy.fit_transform(y_train)\n",
    "y_test =scy.transform(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872281c0-5824-4fda-8d8c-98c23ecdde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 373, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.78891891 0.78833712 0.7806451  0.79766508 0.77137942 0.79638962\n",
      " 0.79208133 0.8012803  0.77278267 0.7782376  0.80715878 0.79126144\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                       'absolute_error', 'poisson'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridserarch - training case data - model creation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {'criterion':['squared_error','friedman_mse','absolute_error','poisson'],'max_features': ['sqrt','log2'],'n_estimators':[50,100]}\n",
    "grid = GridSearchCV(RandomForestRegressor(),param_grid,refit=True,verbose = 3,n_jobs=-1)\n",
    "grid.fit(x_train,y_train)  # in this \"fit\" model creating - values substituion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26e4c3b7-b028-449a-9b0d-151a99a70e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08016648, 0.16513414, 0.08149133, 0.14565167, 0.07688956,\n",
       "        0.14875617, 0.07536159, 0.14778447, 0.07691398, 0.16387024,\n",
       "        0.08941994, 0.14356966, 0.        , 0.0006557 , 0.00076303,\n",
       "        0.00062227]),\n",
       " 'std_fit_time': array([0.00641915, 0.0135358 , 0.00722848, 0.00226052, 0.00331547,\n",
       "        0.00262552, 0.00398741, 0.00272545, 0.00530445, 0.00557987,\n",
       "        0.00665292, 0.00961297, 0.        , 0.00107893, 0.00067789,\n",
       "        0.00124454]),\n",
       " 'mean_score_time': array([0.00643978, 0.00362592, 0.00322251, 0.00548296, 0.00200877,\n",
       "        0.00826569, 0.00506978, 0.0059998 , 0.00817585, 0.00881066,\n",
       "        0.00305033, 0.00449476, 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'std_score_time': array([0.00447863, 0.00321243, 0.00351274, 0.00372932, 0.00310832,\n",
       "        0.00266511, 0.00423679, 0.00334448, 0.00309782, 0.00298108,\n",
       "        0.00221707, 0.00470579, 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'absolute_error',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'poisson', 'poisson', 'poisson', 'poisson'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt', 'log2',\n",
       "                    'log2', 'sqrt', 'sqrt', 'log2', 'log2', 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
       "                    50, 100, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'squared_error',\n",
       "   'max_features': 'sqrt',\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.87793374, 0.90446003, 0.92398586, 0.90231356, 0.90157337,\n",
       "        0.89606828, 0.92029822, 0.90522307, 0.94280982, 0.92613436,\n",
       "        0.85290747, 0.88497867,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'split1_test_score': array([0.88911956, 0.85108625, 0.85037541, 0.87776833, 0.81822023,\n",
       "        0.86811071, 0.83435056, 0.8605208 , 0.90950935, 0.89047496,\n",
       "        0.90995829, 0.87407327,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'split2_test_score': array([0.82684099, 0.81816589, 0.83174008, 0.80035429, 0.77296772,\n",
       "        0.79400529, 0.81211648, 0.83249053, 0.84270502, 0.83320122,\n",
       "        0.82652072, 0.81099937,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'split3_test_score': array([0.48764374, 0.52555266, 0.47111479, 0.58565671, 0.53052567,\n",
       "        0.6111017 , 0.56256464, 0.56668416, 0.34054114, 0.4160442 ,\n",
       "        0.56578349, 0.56725503,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'split4_test_score': array([0.86305651, 0.84242079, 0.82600938, 0.82223249, 0.83361012,\n",
       "        0.81266213, 0.83107676, 0.84148294, 0.82834802, 0.82533328,\n",
       "        0.88062394, 0.81900089,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'mean_test_score': array([0.78891891, 0.78833712, 0.7806451 , 0.79766508, 0.77137942,\n",
       "        0.79638962, 0.79208133, 0.8012803 , 0.77278267, 0.7782376 ,\n",
       "        0.80715878, 0.79126144,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'std_test_score': array([0.15209537, 0.13438188, 0.15867358, 0.11218393, 0.12730298,\n",
       "        0.09968133, 0.12068655, 0.11994934, 0.22018756, 0.18487495,\n",
       "        0.1238505 , 0.11573992,        nan,        nan,        nan,\n",
       "               nan]),\n",
       " 'rank_test_score': array([ 7,  8,  9,  3, 12,  4,  5,  2, 11, 10,  1,  6, 13, 13, 13, 13])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e804eb4d-44f9-4d22-aaf6-f0eb5e44a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080166</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.004479</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.877934</td>\n",
       "      <td>0.889120</td>\n",
       "      <td>0.826841</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>0.863057</td>\n",
       "      <td>0.788919</td>\n",
       "      <td>0.152095</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.165134</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.904460</td>\n",
       "      <td>0.851086</td>\n",
       "      <td>0.818166</td>\n",
       "      <td>0.525553</td>\n",
       "      <td>0.842421</td>\n",
       "      <td>0.788337</td>\n",
       "      <td>0.134382</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.923986</td>\n",
       "      <td>0.850375</td>\n",
       "      <td>0.831740</td>\n",
       "      <td>0.471115</td>\n",
       "      <td>0.826009</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.158674</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145652</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.902314</td>\n",
       "      <td>0.877768</td>\n",
       "      <td>0.800354</td>\n",
       "      <td>0.585657</td>\n",
       "      <td>0.822232</td>\n",
       "      <td>0.797665</td>\n",
       "      <td>0.112184</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076890</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.901573</td>\n",
       "      <td>0.818220</td>\n",
       "      <td>0.772968</td>\n",
       "      <td>0.530526</td>\n",
       "      <td>0.833610</td>\n",
       "      <td>0.771379</td>\n",
       "      <td>0.127303</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.148756</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.896068</td>\n",
       "      <td>0.868111</td>\n",
       "      <td>0.794005</td>\n",
       "      <td>0.611102</td>\n",
       "      <td>0.812662</td>\n",
       "      <td>0.796390</td>\n",
       "      <td>0.099681</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.920298</td>\n",
       "      <td>0.834351</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>0.562565</td>\n",
       "      <td>0.831077</td>\n",
       "      <td>0.792081</td>\n",
       "      <td>0.120687</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.147784</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.905223</td>\n",
       "      <td>0.860521</td>\n",
       "      <td>0.832491</td>\n",
       "      <td>0.566684</td>\n",
       "      <td>0.841483</td>\n",
       "      <td>0.801280</td>\n",
       "      <td>0.119949</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.076914</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.942810</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.842705</td>\n",
       "      <td>0.340541</td>\n",
       "      <td>0.828348</td>\n",
       "      <td>0.772783</td>\n",
       "      <td>0.220188</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.163870</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.926134</td>\n",
       "      <td>0.890475</td>\n",
       "      <td>0.833201</td>\n",
       "      <td>0.416044</td>\n",
       "      <td>0.825333</td>\n",
       "      <td>0.778238</td>\n",
       "      <td>0.184875</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.089420</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.852907</td>\n",
       "      <td>0.909958</td>\n",
       "      <td>0.826521</td>\n",
       "      <td>0.565783</td>\n",
       "      <td>0.880624</td>\n",
       "      <td>0.807159</td>\n",
       "      <td>0.123850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.884979</td>\n",
       "      <td>0.874073</td>\n",
       "      <td>0.810999</td>\n",
       "      <td>0.567255</td>\n",
       "      <td>0.819001</td>\n",
       "      <td>0.791261</td>\n",
       "      <td>0.115740</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.080166      0.006419         0.006440        0.004479   \n",
       "1        0.165134      0.013536         0.003626        0.003212   \n",
       "2        0.081491      0.007228         0.003223        0.003513   \n",
       "3        0.145652      0.002261         0.005483        0.003729   \n",
       "4        0.076890      0.003315         0.002009        0.003108   \n",
       "5        0.148756      0.002626         0.008266        0.002665   \n",
       "6        0.075362      0.003987         0.005070        0.004237   \n",
       "7        0.147784      0.002725         0.006000        0.003344   \n",
       "8        0.076914      0.005304         0.008176        0.003098   \n",
       "9        0.163870      0.005580         0.008811        0.002981   \n",
       "10       0.089420      0.006653         0.003050        0.002217   \n",
       "11       0.143570      0.009613         0.004495        0.004706   \n",
       "12       0.000000      0.000000         0.000000        0.000000   \n",
       "13       0.000656      0.001079         0.000000        0.000000   \n",
       "14       0.000763      0.000678         0.000000        0.000000   \n",
       "15       0.000622      0.001245         0.000000        0.000000   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0    squared_error               sqrt                 50   \n",
       "1    squared_error               sqrt                100   \n",
       "2    squared_error               log2                 50   \n",
       "3    squared_error               log2                100   \n",
       "4     friedman_mse               sqrt                 50   \n",
       "5     friedman_mse               sqrt                100   \n",
       "6     friedman_mse               log2                 50   \n",
       "7     friedman_mse               log2                100   \n",
       "8   absolute_error               sqrt                 50   \n",
       "9   absolute_error               sqrt                100   \n",
       "10  absolute_error               log2                 50   \n",
       "11  absolute_error               log2                100   \n",
       "12         poisson               sqrt                 50   \n",
       "13         poisson               sqrt                100   \n",
       "14         poisson               log2                 50   \n",
       "15         poisson               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_features':...           0.877934   \n",
       "1   {'criterion': 'squared_error', 'max_features':...           0.904460   \n",
       "2   {'criterion': 'squared_error', 'max_features':...           0.923986   \n",
       "3   {'criterion': 'squared_error', 'max_features':...           0.902314   \n",
       "4   {'criterion': 'friedman_mse', 'max_features': ...           0.901573   \n",
       "5   {'criterion': 'friedman_mse', 'max_features': ...           0.896068   \n",
       "6   {'criterion': 'friedman_mse', 'max_features': ...           0.920298   \n",
       "7   {'criterion': 'friedman_mse', 'max_features': ...           0.905223   \n",
       "8   {'criterion': 'absolute_error', 'max_features'...           0.942810   \n",
       "9   {'criterion': 'absolute_error', 'max_features'...           0.926134   \n",
       "10  {'criterion': 'absolute_error', 'max_features'...           0.852907   \n",
       "11  {'criterion': 'absolute_error', 'max_features'...           0.884979   \n",
       "12  {'criterion': 'poisson', 'max_features': 'sqrt...                NaN   \n",
       "13  {'criterion': 'poisson', 'max_features': 'sqrt...                NaN   \n",
       "14  {'criterion': 'poisson', 'max_features': 'log2...                NaN   \n",
       "15  {'criterion': 'poisson', 'max_features': 'log2...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.889120           0.826841           0.487644   \n",
       "1            0.851086           0.818166           0.525553   \n",
       "2            0.850375           0.831740           0.471115   \n",
       "3            0.877768           0.800354           0.585657   \n",
       "4            0.818220           0.772968           0.530526   \n",
       "5            0.868111           0.794005           0.611102   \n",
       "6            0.834351           0.812116           0.562565   \n",
       "7            0.860521           0.832491           0.566684   \n",
       "8            0.909509           0.842705           0.340541   \n",
       "9            0.890475           0.833201           0.416044   \n",
       "10           0.909958           0.826521           0.565783   \n",
       "11           0.874073           0.810999           0.567255   \n",
       "12                NaN                NaN                NaN   \n",
       "13                NaN                NaN                NaN   \n",
       "14                NaN                NaN                NaN   \n",
       "15                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.863057         0.788919        0.152095                7  \n",
       "1            0.842421         0.788337        0.134382                8  \n",
       "2            0.826009         0.780645        0.158674                9  \n",
       "3            0.822232         0.797665        0.112184                3  \n",
       "4            0.833610         0.771379        0.127303               12  \n",
       "5            0.812662         0.796390        0.099681                4  \n",
       "6            0.831077         0.792081        0.120687                5  \n",
       "7            0.841483         0.801280        0.119949                2  \n",
       "8            0.828348         0.772783        0.220188               11  \n",
       "9            0.825333         0.778238        0.184875               10  \n",
       "10           0.880624         0.807159        0.123850                1  \n",
       "11           0.819001         0.791261        0.115740                6  \n",
       "12                NaN              NaN             NaN               13  \n",
       "13                NaN              NaN             NaN               13  \n",
       "14                NaN              NaN             NaN               13  \n",
       "15                NaN              NaN             NaN               13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3966cc5f-fae4-4b10-99b2-e7407633a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction=grid.predict(x_test)\n",
    "#x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ee6e21-7bb3-4884-ae0a-203ec2d64b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7586739891963152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(y_test,grid_prediction)\n",
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52be0f92-88f4-41e7-abe3-39de4400dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"finalized_model_RF_IO.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37aa14b5-31e7-4dbf-8111-e82ccc14717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705ddcd0-3539-4051-850b-ff8617fc02da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.49374843, -4.80327375, -1.53809178,  2.        ,  1.30088727]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput=sc.transform([[22,23.4,0,1,1]])\n",
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4e0d4c7-9ef0-438b-8394-eb9f3de29b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_RF_IO.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa1a0b4a-cb77-4af3-99d4-37549b287cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4154978])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f10f47-670b-48ff-b08f-516732a6c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49340.8508]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preoutput=scy.inverse_transform([result])\n",
    "preoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a2f01c7-a0a0-4649-b766-8461b320aae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8eea39-5016-4768-954d-c50a642550a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
