{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab5102d-8ab8-4fe8-b0cb-847d14f7a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ef33d6-7b06-453f-a3f2-eaf7f3b4cd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")\n",
    "dataset\n",
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67642532-cfad-4ab6-bc86-4e9697b35c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b5a889-629d-4d7a-9640-35e444de1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataset[['R&D Spend', 'Administration', 'Marketing Spend','State_Florida', 'State_New York']]\n",
    "dependent = dataset[['Profit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82731406-30d2-4689-add3-6f7bc4b38ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Set Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(independent,dependent,test_size =0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91b9a9f-d33d-4c1d-9e32-e703f46221f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data preprocessing standarsdization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "# x_train  # pre processed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872281c0-5824-4fda-8d8c-98c23ecdde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                       'absolute_error', 'poisson'],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridserarch - training case data - model creation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {'criterion':['squared_error','friedman_mse','absolute_error','poisson'],'max_features': [None,'sqrt','log2'],'n_estimators':[50,100]}\n",
    "grid = GridSearchCV(RandomForestRegressor(),param_grid,refit=True,verbose = 3,n_jobs=-1)\n",
    "grid.fit(x_train,y_train)  # in this \"fit\" model creating - values substituion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e4c3b7-b028-449a-9b0d-151a99a70e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07641401, 0.14309101, 0.07005033, 0.13920846, 0.07310572,\n",
       "        0.1389607 , 0.07670112, 0.14534693, 0.07368984, 0.14071927,\n",
       "        0.0704474 , 0.13919101, 0.07955236, 0.16067953, 0.07478137,\n",
       "        0.14844713, 0.0755012 , 0.15131984, 0.07351899, 0.14561181,\n",
       "        0.07464614, 0.14435596, 0.07434983, 0.11759586]),\n",
       " 'std_fit_time': array([0.00424846, 0.00397505, 0.00081448, 0.00402349, 0.00425343,\n",
       "        0.00466422, 0.00738517, 0.0052897 , 0.0033958 , 0.00144287,\n",
       "        0.00028475, 0.0033801 , 0.00334686, 0.00527756, 0.00393523,\n",
       "        0.00306073, 0.00375201, 0.00407084, 0.00317768, 0.00317722,\n",
       "        0.00452863, 0.00441321, 0.00351806, 0.0108184 ]),\n",
       " 'mean_score_time': array([0.00455689, 0.01015468, 0.00523715, 0.00914736, 0.00725913,\n",
       "        0.00962892, 0.        , 0.00795178, 0.00213871, 0.00686154,\n",
       "        0.00762801, 0.00844531, 0.00201497, 0.00663977, 0.00672941,\n",
       "        0.00926795, 0.00683918, 0.00900826, 0.00849471, 0.0084424 ,\n",
       "        0.00562201, 0.00878668, 0.0038938 , 0.00643549]),\n",
       " 'std_score_time': array([0.00480369, 0.00014813, 0.00394602, 0.00122318, 0.00302683,\n",
       "        0.00082551, 0.        , 0.00296479, 0.0019057 , 0.0039577 ,\n",
       "        0.00294722, 0.00321405, 0.00402994, 0.00396876, 0.00476565,\n",
       "        0.00396504, 0.0039406 , 0.00101339, 0.00199379, 0.00321438,\n",
       "        0.00464999, 0.00351798, 0.00372476, 0.00447158]),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'poisson', 'poisson', 'poisson', 'poisson', 'poisson',\n",
       "                    'poisson'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', None, None, 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
       "                    50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'squared_error',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.86545736, 0.87660076, 0.90686069, 0.91262243, 0.93359835,\n",
       "        0.92876664, 0.89342044, 0.87936876, 0.91040384, 0.92568813,\n",
       "        0.92365634, 0.91665734, 0.87234481, 0.8572936 , 0.91032411,\n",
       "        0.9141576 , 0.93027319, 0.91741197, 0.88391747, 0.88780352,\n",
       "        0.90795028, 0.92165686, 0.937078  , 0.92280746]),\n",
       " 'split1_test_score': array([0.86972026, 0.88762737, 0.84064499, 0.85635416, 0.90289135,\n",
       "        0.86515666, 0.88914023, 0.9075138 , 0.83195441, 0.88231734,\n",
       "        0.69771856, 0.88142217, 0.92198517, 0.90412972, 0.90537477,\n",
       "        0.88356683, 0.83180011, 0.85496661, 0.92198094, 0.91094638,\n",
       "        0.8906435 , 0.87425091, 0.79813171, 0.90171022]),\n",
       " 'split2_test_score': array([0.90878317, 0.90111919, 0.78171478, 0.82223069, 0.81611694,\n",
       "        0.82761454, 0.906203  , 0.91031021, 0.85457809, 0.79728423,\n",
       "        0.85579901, 0.8267284 , 0.90517809, 0.91396129, 0.82035318,\n",
       "        0.83687414, 0.80289055, 0.83329855, 0.89482496, 0.89986179,\n",
       "        0.78534214, 0.84817673, 0.78373534, 0.79901923]),\n",
       " 'split3_test_score': array([0.71577499, 0.63296645, 0.6208977 , 0.3670532 , 0.38245637,\n",
       "        0.47115004, 0.59656046, 0.74629574, 0.496771  , 0.41161499,\n",
       "        0.40482946, 0.44430515, 0.62810389, 0.73440281, 0.39591065,\n",
       "        0.45273338, 0.49663858, 0.48323366, 0.53730902, 0.61648529,\n",
       "        0.31222077, 0.32688145, 0.35643192, 0.22065054]),\n",
       " 'split4_test_score': array([0.94864453, 0.94181013, 0.83492889, 0.81664233, 0.79106708,\n",
       "        0.83186411, 0.94230733, 0.9376111 , 0.79579751, 0.8451931 ,\n",
       "        0.80070756, 0.82169595, 0.94020208, 0.93912345, 0.80732055,\n",
       "        0.83797553, 0.88708567, 0.85712103, 0.94297799, 0.94788823,\n",
       "        0.8378976 , 0.80887914, 0.83876084, 0.83238877]),\n",
       " 'mean_test_score': array([0.86167606, 0.84802478, 0.79700941, 0.75498056, 0.76522602,\n",
       "        0.7849104 , 0.84552629, 0.87621992, 0.77790097, 0.77241956,\n",
       "        0.73654219, 0.7781618 , 0.85356281, 0.86978217, 0.76785665,\n",
       "        0.7850615 , 0.78973762, 0.78920636, 0.83620208, 0.85259704,\n",
       "        0.74681086, 0.75596902, 0.74282756, 0.73531524]),\n",
       " 'std_test_score': array([0.07892873, 0.10977226, 0.09660074, 0.19694667, 0.19853022,\n",
       "        0.16100182, 0.1258795 , 0.06752857, 0.14540462, 0.18529056,\n",
       "        0.18159939, 0.17062117, 0.11492311, 0.07269566, 0.19071724,\n",
       "        0.16869827, 0.15302039, 0.15552293, 0.15087052, 0.11975581,\n",
       "        0.22149661, 0.21765153, 0.20048442, 0.26122858]),\n",
       " 'rank_test_score': array([ 3,  6,  9, 20, 18, 13,  7,  1, 15, 16, 23, 14,  4,  2, 17, 12, 10,\n",
       "        11,  8,  5, 21, 19, 22, 24])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e804eb4d-44f9-4d22-aaf6-f0eb5e44a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076414</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.865457</td>\n",
       "      <td>0.869720</td>\n",
       "      <td>0.908783</td>\n",
       "      <td>0.715775</td>\n",
       "      <td>0.948645</td>\n",
       "      <td>0.861676</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143091</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.876601</td>\n",
       "      <td>0.887627</td>\n",
       "      <td>0.901119</td>\n",
       "      <td>0.632966</td>\n",
       "      <td>0.941810</td>\n",
       "      <td>0.848025</td>\n",
       "      <td>0.109772</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.906861</td>\n",
       "      <td>0.840645</td>\n",
       "      <td>0.781715</td>\n",
       "      <td>0.620898</td>\n",
       "      <td>0.834929</td>\n",
       "      <td>0.797009</td>\n",
       "      <td>0.096601</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139208</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.912622</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.822231</td>\n",
       "      <td>0.367053</td>\n",
       "      <td>0.816642</td>\n",
       "      <td>0.754981</td>\n",
       "      <td>0.196947</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.933598</td>\n",
       "      <td>0.902891</td>\n",
       "      <td>0.816117</td>\n",
       "      <td>0.382456</td>\n",
       "      <td>0.791067</td>\n",
       "      <td>0.765226</td>\n",
       "      <td>0.198530</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138961</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.928767</td>\n",
       "      <td>0.865157</td>\n",
       "      <td>0.827615</td>\n",
       "      <td>0.471150</td>\n",
       "      <td>0.831864</td>\n",
       "      <td>0.784910</td>\n",
       "      <td>0.161002</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.076701</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.893420</td>\n",
       "      <td>0.889140</td>\n",
       "      <td>0.906203</td>\n",
       "      <td>0.596560</td>\n",
       "      <td>0.942307</td>\n",
       "      <td>0.845526</td>\n",
       "      <td>0.125879</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145347</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.879369</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.910310</td>\n",
       "      <td>0.746296</td>\n",
       "      <td>0.937611</td>\n",
       "      <td>0.876220</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.073690</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.910404</td>\n",
       "      <td>0.831954</td>\n",
       "      <td>0.854578</td>\n",
       "      <td>0.496771</td>\n",
       "      <td>0.795798</td>\n",
       "      <td>0.777901</td>\n",
       "      <td>0.145405</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.140719</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.925688</td>\n",
       "      <td>0.882317</td>\n",
       "      <td>0.797284</td>\n",
       "      <td>0.411615</td>\n",
       "      <td>0.845193</td>\n",
       "      <td>0.772420</td>\n",
       "      <td>0.185291</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070447</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.923656</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>0.855799</td>\n",
       "      <td>0.404829</td>\n",
       "      <td>0.800708</td>\n",
       "      <td>0.736542</td>\n",
       "      <td>0.181599</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.139191</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.008445</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.916657</td>\n",
       "      <td>0.881422</td>\n",
       "      <td>0.826728</td>\n",
       "      <td>0.444305</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.778162</td>\n",
       "      <td>0.170621</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.079552</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.872345</td>\n",
       "      <td>0.921985</td>\n",
       "      <td>0.905178</td>\n",
       "      <td>0.628104</td>\n",
       "      <td>0.940202</td>\n",
       "      <td>0.853563</td>\n",
       "      <td>0.114923</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.160680</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>0.904130</td>\n",
       "      <td>0.913961</td>\n",
       "      <td>0.734403</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.869782</td>\n",
       "      <td>0.072696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.074781</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.910324</td>\n",
       "      <td>0.905375</td>\n",
       "      <td>0.820353</td>\n",
       "      <td>0.395911</td>\n",
       "      <td>0.807321</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.190717</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.148447</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.914158</td>\n",
       "      <td>0.883567</td>\n",
       "      <td>0.836874</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.837976</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>0.168698</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.075501</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.930273</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.802891</td>\n",
       "      <td>0.496639</td>\n",
       "      <td>0.887086</td>\n",
       "      <td>0.789738</td>\n",
       "      <td>0.153020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.151320</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.917412</td>\n",
       "      <td>0.854967</td>\n",
       "      <td>0.833299</td>\n",
       "      <td>0.483234</td>\n",
       "      <td>0.857121</td>\n",
       "      <td>0.789206</td>\n",
       "      <td>0.155523</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.073519</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': None,...</td>\n",
       "      <td>0.883917</td>\n",
       "      <td>0.921981</td>\n",
       "      <td>0.894825</td>\n",
       "      <td>0.537309</td>\n",
       "      <td>0.942978</td>\n",
       "      <td>0.836202</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.145612</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': None,...</td>\n",
       "      <td>0.887804</td>\n",
       "      <td>0.910946</td>\n",
       "      <td>0.899862</td>\n",
       "      <td>0.616485</td>\n",
       "      <td>0.947888</td>\n",
       "      <td>0.852597</td>\n",
       "      <td>0.119756</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.074646</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.907950</td>\n",
       "      <td>0.890643</td>\n",
       "      <td>0.785342</td>\n",
       "      <td>0.312221</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.221497</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.144356</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.008787</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>0.921657</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>0.848177</td>\n",
       "      <td>0.326881</td>\n",
       "      <td>0.808879</td>\n",
       "      <td>0.755969</td>\n",
       "      <td>0.217652</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.074350</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.937078</td>\n",
       "      <td>0.798132</td>\n",
       "      <td>0.783735</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>0.838761</td>\n",
       "      <td>0.742828</td>\n",
       "      <td>0.200484</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.117596</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>0.922807</td>\n",
       "      <td>0.901710</td>\n",
       "      <td>0.799019</td>\n",
       "      <td>0.220651</td>\n",
       "      <td>0.832389</td>\n",
       "      <td>0.735315</td>\n",
       "      <td>0.261229</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.076414      0.004248         0.004557        0.004804   \n",
       "1        0.143091      0.003975         0.010155        0.000148   \n",
       "2        0.070050      0.000814         0.005237        0.003946   \n",
       "3        0.139208      0.004023         0.009147        0.001223   \n",
       "4        0.073106      0.004253         0.007259        0.003027   \n",
       "5        0.138961      0.004664         0.009629        0.000826   \n",
       "6        0.076701      0.007385         0.000000        0.000000   \n",
       "7        0.145347      0.005290         0.007952        0.002965   \n",
       "8        0.073690      0.003396         0.002139        0.001906   \n",
       "9        0.140719      0.001443         0.006862        0.003958   \n",
       "10       0.070447      0.000285         0.007628        0.002947   \n",
       "11       0.139191      0.003380         0.008445        0.003214   \n",
       "12       0.079552      0.003347         0.002015        0.004030   \n",
       "13       0.160680      0.005278         0.006640        0.003969   \n",
       "14       0.074781      0.003935         0.006729        0.004766   \n",
       "15       0.148447      0.003061         0.009268        0.003965   \n",
       "16       0.075501      0.003752         0.006839        0.003941   \n",
       "17       0.151320      0.004071         0.009008        0.001013   \n",
       "18       0.073519      0.003178         0.008495        0.001994   \n",
       "19       0.145612      0.003177         0.008442        0.003214   \n",
       "20       0.074646      0.004529         0.005622        0.004650   \n",
       "21       0.144356      0.004413         0.008787        0.003518   \n",
       "22       0.074350      0.003518         0.003894        0.003725   \n",
       "23       0.117596      0.010818         0.006435        0.004472   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0    squared_error               None                 50   \n",
       "1    squared_error               None                100   \n",
       "2    squared_error               sqrt                 50   \n",
       "3    squared_error               sqrt                100   \n",
       "4    squared_error               log2                 50   \n",
       "5    squared_error               log2                100   \n",
       "6     friedman_mse               None                 50   \n",
       "7     friedman_mse               None                100   \n",
       "8     friedman_mse               sqrt                 50   \n",
       "9     friedman_mse               sqrt                100   \n",
       "10    friedman_mse               log2                 50   \n",
       "11    friedman_mse               log2                100   \n",
       "12  absolute_error               None                 50   \n",
       "13  absolute_error               None                100   \n",
       "14  absolute_error               sqrt                 50   \n",
       "15  absolute_error               sqrt                100   \n",
       "16  absolute_error               log2                 50   \n",
       "17  absolute_error               log2                100   \n",
       "18         poisson               None                 50   \n",
       "19         poisson               None                100   \n",
       "20         poisson               sqrt                 50   \n",
       "21         poisson               sqrt                100   \n",
       "22         poisson               log2                 50   \n",
       "23         poisson               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_features':...           0.865457   \n",
       "1   {'criterion': 'squared_error', 'max_features':...           0.876601   \n",
       "2   {'criterion': 'squared_error', 'max_features':...           0.906861   \n",
       "3   {'criterion': 'squared_error', 'max_features':...           0.912622   \n",
       "4   {'criterion': 'squared_error', 'max_features':...           0.933598   \n",
       "5   {'criterion': 'squared_error', 'max_features':...           0.928767   \n",
       "6   {'criterion': 'friedman_mse', 'max_features': ...           0.893420   \n",
       "7   {'criterion': 'friedman_mse', 'max_features': ...           0.879369   \n",
       "8   {'criterion': 'friedman_mse', 'max_features': ...           0.910404   \n",
       "9   {'criterion': 'friedman_mse', 'max_features': ...           0.925688   \n",
       "10  {'criterion': 'friedman_mse', 'max_features': ...           0.923656   \n",
       "11  {'criterion': 'friedman_mse', 'max_features': ...           0.916657   \n",
       "12  {'criterion': 'absolute_error', 'max_features'...           0.872345   \n",
       "13  {'criterion': 'absolute_error', 'max_features'...           0.857294   \n",
       "14  {'criterion': 'absolute_error', 'max_features'...           0.910324   \n",
       "15  {'criterion': 'absolute_error', 'max_features'...           0.914158   \n",
       "16  {'criterion': 'absolute_error', 'max_features'...           0.930273   \n",
       "17  {'criterion': 'absolute_error', 'max_features'...           0.917412   \n",
       "18  {'criterion': 'poisson', 'max_features': None,...           0.883917   \n",
       "19  {'criterion': 'poisson', 'max_features': None,...           0.887804   \n",
       "20  {'criterion': 'poisson', 'max_features': 'sqrt...           0.907950   \n",
       "21  {'criterion': 'poisson', 'max_features': 'sqrt...           0.921657   \n",
       "22  {'criterion': 'poisson', 'max_features': 'log2...           0.937078   \n",
       "23  {'criterion': 'poisson', 'max_features': 'log2...           0.922807   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.869720           0.908783           0.715775   \n",
       "1            0.887627           0.901119           0.632966   \n",
       "2            0.840645           0.781715           0.620898   \n",
       "3            0.856354           0.822231           0.367053   \n",
       "4            0.902891           0.816117           0.382456   \n",
       "5            0.865157           0.827615           0.471150   \n",
       "6            0.889140           0.906203           0.596560   \n",
       "7            0.907514           0.910310           0.746296   \n",
       "8            0.831954           0.854578           0.496771   \n",
       "9            0.882317           0.797284           0.411615   \n",
       "10           0.697719           0.855799           0.404829   \n",
       "11           0.881422           0.826728           0.444305   \n",
       "12           0.921985           0.905178           0.628104   \n",
       "13           0.904130           0.913961           0.734403   \n",
       "14           0.905375           0.820353           0.395911   \n",
       "15           0.883567           0.836874           0.452733   \n",
       "16           0.831800           0.802891           0.496639   \n",
       "17           0.854967           0.833299           0.483234   \n",
       "18           0.921981           0.894825           0.537309   \n",
       "19           0.910946           0.899862           0.616485   \n",
       "20           0.890643           0.785342           0.312221   \n",
       "21           0.874251           0.848177           0.326881   \n",
       "22           0.798132           0.783735           0.356432   \n",
       "23           0.901710           0.799019           0.220651   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.948645         0.861676        0.078929                3  \n",
       "1            0.941810         0.848025        0.109772                6  \n",
       "2            0.834929         0.797009        0.096601                9  \n",
       "3            0.816642         0.754981        0.196947               20  \n",
       "4            0.791067         0.765226        0.198530               18  \n",
       "5            0.831864         0.784910        0.161002               13  \n",
       "6            0.942307         0.845526        0.125879                7  \n",
       "7            0.937611         0.876220        0.067529                1  \n",
       "8            0.795798         0.777901        0.145405               15  \n",
       "9            0.845193         0.772420        0.185291               16  \n",
       "10           0.800708         0.736542        0.181599               23  \n",
       "11           0.821696         0.778162        0.170621               14  \n",
       "12           0.940202         0.853563        0.114923                4  \n",
       "13           0.939123         0.869782        0.072696                2  \n",
       "14           0.807321         0.767857        0.190717               17  \n",
       "15           0.837976         0.785061        0.168698               12  \n",
       "16           0.887086         0.789738        0.153020               10  \n",
       "17           0.857121         0.789206        0.155523               11  \n",
       "18           0.942978         0.836202        0.150871                8  \n",
       "19           0.947888         0.852597        0.119756                5  \n",
       "20           0.837898         0.746811        0.221497               21  \n",
       "21           0.808879         0.755969        0.217652               19  \n",
       "22           0.838761         0.742828        0.200484               22  \n",
       "23           0.832389         0.735315        0.261229               24  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9246f1-e9a9-4da9-ad9f-7bd1886f0a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Score best param{'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 100}:\n"
     ]
    }
   ],
   "source": [
    "print('R_Score best param{}:'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3966cc5f-fae4-4b10-99b2-e7407633a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction=grid.predict(x_test)\n",
    "#x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ee6e21-7bb3-4884-ae0a-203ec2d64b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465695388199485"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(y_test,grid_prediction)\n",
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77920710-fd68-46dd-b697-12a139700ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"Standard_Scaler.pkl\"\n",
    "pickle.dump(sc,open(filename,'wb'))\n",
    "scx=pickle.load(open('Standard_Scaler.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47d47d8-3fca-4466-b914-4829a1fab7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"finalized_model_RandomForest.sav\"\n",
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a6f361-8c29-4611-b1d4-0d1fb5e2f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.49374843, -4.80327375, -1.53809178,  2.        ,  1.30088727]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput=sc.transform([[22,23.4,0,1,1]])\n",
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e27e9f-77f3-413d-ad42-8c8c20f0dc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49292.141])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_RF.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2979864-c016-409b-b4b0-17267417dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e211f87-82c5-43db-8e39-1af48d14bb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
