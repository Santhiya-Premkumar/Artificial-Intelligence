{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab5102d-8ab8-4fe8-b0cb-847d14f7a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ef33d6-7b06-453f-a3f2-eaf7f3b4cd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")\n",
    "dataset\n",
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67642532-cfad-4ab6-bc86-4e9697b35c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b5a889-629d-4d7a-9640-35e444de1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = dataset[['R&D Spend', 'Administration', 'Marketing Spend','State_Florida', 'State_New York']]\n",
    "dependent = dataset[['Profit']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82731406-30d2-4689-add3-6f7bc4b38ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Set Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(independent,dependent,test_size =0.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91b9a9f-d33d-4c1d-9e32-e703f46221f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data preprocessing standarsdization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)\n",
    "x_test=sc.transform(x_test)\n",
    "# x_train  # pre processed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee55ffd-927f-475c-b62e-ab8457e9c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data preprocessing \n",
    "scy=StandardScaler()\n",
    "y_train=scy.fit_transform(y_train)\n",
    "y_test =scy.transform(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872281c0-5824-4fda-8d8c-98c23ecdde23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 373, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84315739 0.8534318  0.78021928 0.7811847  0.77404733 0.76175607\n",
      " 0.83807173 0.83978813 0.75480546 0.76587091 0.7658274  0.77964977\n",
      " 0.87636271 0.8832736  0.83267831 0.78281016 0.77530823 0.76020746\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;, &#x27;poisson&#x27;],\n",
       "                         &#x27;max_features&#x27;: [None, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                       'absolute_error', 'poisson'],\n",
       "                         'max_features': [None, 'sqrt', 'log2'],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridserarch - training case data - model creation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {'criterion':['squared_error','friedman_mse','absolute_error','poisson'],'max_features': [None,'sqrt','log2'],'n_estimators':[50,100]}\n",
    "grid = GridSearchCV(RandomForestRegressor(),param_grid,refit=True,verbose = 3,n_jobs=-1)\n",
    "grid.fit(x_train,y_train)  # in this \"fit\" model creating - values substituion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e4c3b7-b028-449a-9b0d-151a99a70e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.09520259, 0.16480198, 0.07908025, 0.14161477, 0.07520905,\n",
       "        0.14687147, 0.08007488, 0.15797324, 0.08285899, 0.15503163,\n",
       "        0.09168215, 0.15537972, 0.10394745, 0.16930494, 0.07664223,\n",
       "        0.15957379, 0.08204966, 0.14148126, 0.00220656, 0.00079312,\n",
       "        0.0005794 , 0.00078206, 0.0006424 , 0.00101976]),\n",
       " 'std_fit_time': array([0.00872447, 0.01293933, 0.01370677, 0.0026327 , 0.00578516,\n",
       "        0.00279104, 0.00127565, 0.00604152, 0.00271349, 0.00268399,\n",
       "        0.00947804, 0.00316658, 0.01147282, 0.00843928, 0.00230907,\n",
       "        0.00606639, 0.00655466, 0.01018223, 0.00313193, 0.00134959,\n",
       "        0.0005475 , 0.00156412, 0.00044943, 0.00070169]),\n",
       " 'mean_score_time': array([0.00645866, 0.00743184, 0.00542645, 0.0081234 , 0.00442772,\n",
       "        0.00897293, 0.00365639, 0.00681119, 0.0042407 , 0.00954361,\n",
       "        0.00682268, 0.01183534, 0.00373201, 0.00964065, 0.00442123,\n",
       "        0.00950212, 0.00329351, 0.00353127, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'std_score_time': array([0.00449522, 0.00294652, 0.00456291, 0.00170256, 0.00465851,\n",
       "        0.00186871, 0.0029226 , 0.00527845, 0.00283563, 0.00250171,\n",
       "        0.0040207 , 0.00610789, 0.0036355 , 0.00080999, 0.00465014,\n",
       "        0.0014682 , 0.00374235, 0.00320171, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'friedman_mse', 'friedman_mse', 'friedman_mse',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'absolute_error', 'absolute_error', 'absolute_error',\n",
       "                    'poisson', 'poisson', 'poisson', 'poisson', 'poisson',\n",
       "                    'poisson'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[None, None, 'sqrt', 'sqrt', 'log2', 'log2', None, None,\n",
       "                    'sqrt', 'sqrt', 'log2', 'log2', None, None, 'sqrt',\n",
       "                    'sqrt', 'log2', 'log2', None, None, 'sqrt', 'sqrt',\n",
       "                    'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,\n",
       "                    50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'squared_error',\n",
       "   'max_features': None,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'squared_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'friedman_mse', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'absolute_error', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': None, 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': None, 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'sqrt', 'n_estimators': 100},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 50},\n",
       "  {'criterion': 'poisson', 'max_features': 'log2', 'n_estimators': 100}],\n",
       " 'split0_test_score': array([0.80249398, 0.8755945 , 0.92767976, 0.91247474, 0.90570625,\n",
       "        0.91377753, 0.87216583, 0.84563517, 0.9043255 , 0.923975  ,\n",
       "        0.91996872, 0.92787065, 0.8850044 , 0.87611904, 0.92306354,\n",
       "        0.92323702, 0.9285229 , 0.92576689,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split1_test_score': array([0.91634461, 0.88361269, 0.86225839, 0.85928298, 0.78156633,\n",
       "        0.88032286, 0.90312622, 0.89777243, 0.92847882, 0.826626  ,\n",
       "        0.8475064 , 0.82604646, 0.90802572, 0.90574116, 0.91936337,\n",
       "        0.81826075, 0.86787692, 0.85156035,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split2_test_score': array([0.9040447 , 0.90797989, 0.81795516, 0.81546987, 0.79643307,\n",
       "        0.83904554, 0.8922008 , 0.89846425, 0.81824943, 0.82038867,\n",
       "        0.84336991, 0.83411766, 0.90684878, 0.90838582, 0.84197315,\n",
       "        0.81609759, 0.80572696, 0.84149958,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split3_test_score': array([0.64604449, 0.65405121, 0.46351931, 0.51135727, 0.53643189,\n",
       "        0.37392562, 0.58438451, 0.62527451, 0.32269483, 0.46395717,\n",
       "        0.41947364, 0.46777165, 0.73661319, 0.779908  , 0.63389425,\n",
       "        0.54748863, 0.44500178, 0.3711156 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split4_test_score': array([0.9468592 , 0.94592073, 0.82968378, 0.80733862, 0.8500991 ,\n",
       "        0.80170882, 0.93848128, 0.93179427, 0.80027871, 0.79440774,\n",
       "        0.79881832, 0.84244241, 0.94532147, 0.94621397, 0.84509727,\n",
       "        0.8089668 , 0.8294126 , 0.8110949 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'mean_test_score': array([0.84315739, 0.8534318 , 0.78021928, 0.7811847 , 0.77404733,\n",
       "        0.76175607, 0.83807173, 0.83978813, 0.75480546, 0.76587091,\n",
       "        0.7658274 , 0.77964977, 0.87636271, 0.8832736 , 0.83267831,\n",
       "        0.78281016, 0.77530823, 0.76020746,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'std_test_score': array([0.10984053, 0.10264929, 0.16287702, 0.14000197, 0.12659913,\n",
       "        0.1975606 , 0.12865748, 0.11074338, 0.22150902, 0.15724282,\n",
       "        0.17747855, 0.16018721, 0.07251464, 0.05627173, 0.10529911,\n",
       "        0.12501591, 0.17029306, 0.19816442,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'rank_test_score': array([ 4,  3, 10,  9, 13, 16,  6,  5, 18, 14, 15, 11,  2,  1,  7,  8, 12,\n",
       "        17, 19, 19, 19, 19, 19, 19])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re=grid.cv_results_\n",
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e804eb4d-44f9-4d22-aaf6-f0eb5e44a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095203</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.802494</td>\n",
       "      <td>0.916345</td>\n",
       "      <td>0.904045</td>\n",
       "      <td>0.646044</td>\n",
       "      <td>0.946859</td>\n",
       "      <td>0.843157</td>\n",
       "      <td>0.109841</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164802</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.875595</td>\n",
       "      <td>0.883613</td>\n",
       "      <td>0.907980</td>\n",
       "      <td>0.654051</td>\n",
       "      <td>0.945921</td>\n",
       "      <td>0.853432</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079080</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.927680</td>\n",
       "      <td>0.862258</td>\n",
       "      <td>0.817955</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.829684</td>\n",
       "      <td>0.780219</td>\n",
       "      <td>0.162877</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141615</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.912475</td>\n",
       "      <td>0.859283</td>\n",
       "      <td>0.815470</td>\n",
       "      <td>0.511357</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.781185</td>\n",
       "      <td>0.140002</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075209</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.905706</td>\n",
       "      <td>0.781566</td>\n",
       "      <td>0.796433</td>\n",
       "      <td>0.536432</td>\n",
       "      <td>0.850099</td>\n",
       "      <td>0.774047</td>\n",
       "      <td>0.126599</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.146871</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_features':...</td>\n",
       "      <td>0.913778</td>\n",
       "      <td>0.880323</td>\n",
       "      <td>0.839046</td>\n",
       "      <td>0.373926</td>\n",
       "      <td>0.801709</td>\n",
       "      <td>0.761756</td>\n",
       "      <td>0.197561</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080075</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.872166</td>\n",
       "      <td>0.903126</td>\n",
       "      <td>0.892201</td>\n",
       "      <td>0.584385</td>\n",
       "      <td>0.938481</td>\n",
       "      <td>0.838072</td>\n",
       "      <td>0.128657</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.845635</td>\n",
       "      <td>0.897772</td>\n",
       "      <td>0.898464</td>\n",
       "      <td>0.625275</td>\n",
       "      <td>0.931794</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.110743</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.082859</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.904326</td>\n",
       "      <td>0.928479</td>\n",
       "      <td>0.818249</td>\n",
       "      <td>0.322695</td>\n",
       "      <td>0.800279</td>\n",
       "      <td>0.754805</td>\n",
       "      <td>0.221509</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.155032</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.923975</td>\n",
       "      <td>0.826626</td>\n",
       "      <td>0.820389</td>\n",
       "      <td>0.463957</td>\n",
       "      <td>0.794408</td>\n",
       "      <td>0.765871</td>\n",
       "      <td>0.157243</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.091682</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.919969</td>\n",
       "      <td>0.847506</td>\n",
       "      <td>0.843370</td>\n",
       "      <td>0.419474</td>\n",
       "      <td>0.798818</td>\n",
       "      <td>0.765827</td>\n",
       "      <td>0.177479</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.155380</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_features': ...</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>0.826046</td>\n",
       "      <td>0.834118</td>\n",
       "      <td>0.467772</td>\n",
       "      <td>0.842442</td>\n",
       "      <td>0.779650</td>\n",
       "      <td>0.160187</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.103947</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.885004</td>\n",
       "      <td>0.908026</td>\n",
       "      <td>0.906849</td>\n",
       "      <td>0.736613</td>\n",
       "      <td>0.945321</td>\n",
       "      <td>0.876363</td>\n",
       "      <td>0.072515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.169305</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.876119</td>\n",
       "      <td>0.905741</td>\n",
       "      <td>0.908386</td>\n",
       "      <td>0.779908</td>\n",
       "      <td>0.946214</td>\n",
       "      <td>0.883274</td>\n",
       "      <td>0.056272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.076642</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.923064</td>\n",
       "      <td>0.919363</td>\n",
       "      <td>0.841973</td>\n",
       "      <td>0.633894</td>\n",
       "      <td>0.845097</td>\n",
       "      <td>0.832678</td>\n",
       "      <td>0.105299</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.159574</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.923237</td>\n",
       "      <td>0.818261</td>\n",
       "      <td>0.816098</td>\n",
       "      <td>0.547489</td>\n",
       "      <td>0.808967</td>\n",
       "      <td>0.782810</td>\n",
       "      <td>0.125016</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.082050</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.928523</td>\n",
       "      <td>0.867877</td>\n",
       "      <td>0.805727</td>\n",
       "      <td>0.445002</td>\n",
       "      <td>0.829413</td>\n",
       "      <td>0.775308</td>\n",
       "      <td>0.170293</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.141481</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_features'...</td>\n",
       "      <td>0.925767</td>\n",
       "      <td>0.851560</td>\n",
       "      <td>0.841500</td>\n",
       "      <td>0.371116</td>\n",
       "      <td>0.811095</td>\n",
       "      <td>0.760207</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': None,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': None,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'sqrt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>poisson</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_features': 'log2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.095203      0.008724         0.006459        0.004495   \n",
       "1        0.164802      0.012939         0.007432        0.002947   \n",
       "2        0.079080      0.013707         0.005426        0.004563   \n",
       "3        0.141615      0.002633         0.008123        0.001703   \n",
       "4        0.075209      0.005785         0.004428        0.004659   \n",
       "5        0.146871      0.002791         0.008973        0.001869   \n",
       "6        0.080075      0.001276         0.003656        0.002923   \n",
       "7        0.157973      0.006042         0.006811        0.005278   \n",
       "8        0.082859      0.002713         0.004241        0.002836   \n",
       "9        0.155032      0.002684         0.009544        0.002502   \n",
       "10       0.091682      0.009478         0.006823        0.004021   \n",
       "11       0.155380      0.003167         0.011835        0.006108   \n",
       "12       0.103947      0.011473         0.003732        0.003636   \n",
       "13       0.169305      0.008439         0.009641        0.000810   \n",
       "14       0.076642      0.002309         0.004421        0.004650   \n",
       "15       0.159574      0.006066         0.009502        0.001468   \n",
       "16       0.082050      0.006555         0.003294        0.003742   \n",
       "17       0.141481      0.010182         0.003531        0.003202   \n",
       "18       0.002207      0.003132         0.000000        0.000000   \n",
       "19       0.000793      0.001350         0.000000        0.000000   \n",
       "20       0.000579      0.000547         0.000000        0.000000   \n",
       "21       0.000782      0.001564         0.000000        0.000000   \n",
       "22       0.000642      0.000449         0.000000        0.000000   \n",
       "23       0.001020      0.000702         0.000000        0.000000   \n",
       "\n",
       "   param_criterion param_max_features param_n_estimators  \\\n",
       "0    squared_error               None                 50   \n",
       "1    squared_error               None                100   \n",
       "2    squared_error               sqrt                 50   \n",
       "3    squared_error               sqrt                100   \n",
       "4    squared_error               log2                 50   \n",
       "5    squared_error               log2                100   \n",
       "6     friedman_mse               None                 50   \n",
       "7     friedman_mse               None                100   \n",
       "8     friedman_mse               sqrt                 50   \n",
       "9     friedman_mse               sqrt                100   \n",
       "10    friedman_mse               log2                 50   \n",
       "11    friedman_mse               log2                100   \n",
       "12  absolute_error               None                 50   \n",
       "13  absolute_error               None                100   \n",
       "14  absolute_error               sqrt                 50   \n",
       "15  absolute_error               sqrt                100   \n",
       "16  absolute_error               log2                 50   \n",
       "17  absolute_error               log2                100   \n",
       "18         poisson               None                 50   \n",
       "19         poisson               None                100   \n",
       "20         poisson               sqrt                 50   \n",
       "21         poisson               sqrt                100   \n",
       "22         poisson               log2                 50   \n",
       "23         poisson               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_features':...           0.802494   \n",
       "1   {'criterion': 'squared_error', 'max_features':...           0.875595   \n",
       "2   {'criterion': 'squared_error', 'max_features':...           0.927680   \n",
       "3   {'criterion': 'squared_error', 'max_features':...           0.912475   \n",
       "4   {'criterion': 'squared_error', 'max_features':...           0.905706   \n",
       "5   {'criterion': 'squared_error', 'max_features':...           0.913778   \n",
       "6   {'criterion': 'friedman_mse', 'max_features': ...           0.872166   \n",
       "7   {'criterion': 'friedman_mse', 'max_features': ...           0.845635   \n",
       "8   {'criterion': 'friedman_mse', 'max_features': ...           0.904326   \n",
       "9   {'criterion': 'friedman_mse', 'max_features': ...           0.923975   \n",
       "10  {'criterion': 'friedman_mse', 'max_features': ...           0.919969   \n",
       "11  {'criterion': 'friedman_mse', 'max_features': ...           0.927871   \n",
       "12  {'criterion': 'absolute_error', 'max_features'...           0.885004   \n",
       "13  {'criterion': 'absolute_error', 'max_features'...           0.876119   \n",
       "14  {'criterion': 'absolute_error', 'max_features'...           0.923064   \n",
       "15  {'criterion': 'absolute_error', 'max_features'...           0.923237   \n",
       "16  {'criterion': 'absolute_error', 'max_features'...           0.928523   \n",
       "17  {'criterion': 'absolute_error', 'max_features'...           0.925767   \n",
       "18  {'criterion': 'poisson', 'max_features': None,...                NaN   \n",
       "19  {'criterion': 'poisson', 'max_features': None,...                NaN   \n",
       "20  {'criterion': 'poisson', 'max_features': 'sqrt...                NaN   \n",
       "21  {'criterion': 'poisson', 'max_features': 'sqrt...                NaN   \n",
       "22  {'criterion': 'poisson', 'max_features': 'log2...                NaN   \n",
       "23  {'criterion': 'poisson', 'max_features': 'log2...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.916345           0.904045           0.646044   \n",
       "1            0.883613           0.907980           0.654051   \n",
       "2            0.862258           0.817955           0.463519   \n",
       "3            0.859283           0.815470           0.511357   \n",
       "4            0.781566           0.796433           0.536432   \n",
       "5            0.880323           0.839046           0.373926   \n",
       "6            0.903126           0.892201           0.584385   \n",
       "7            0.897772           0.898464           0.625275   \n",
       "8            0.928479           0.818249           0.322695   \n",
       "9            0.826626           0.820389           0.463957   \n",
       "10           0.847506           0.843370           0.419474   \n",
       "11           0.826046           0.834118           0.467772   \n",
       "12           0.908026           0.906849           0.736613   \n",
       "13           0.905741           0.908386           0.779908   \n",
       "14           0.919363           0.841973           0.633894   \n",
       "15           0.818261           0.816098           0.547489   \n",
       "16           0.867877           0.805727           0.445002   \n",
       "17           0.851560           0.841500           0.371116   \n",
       "18                NaN                NaN                NaN   \n",
       "19                NaN                NaN                NaN   \n",
       "20                NaN                NaN                NaN   \n",
       "21                NaN                NaN                NaN   \n",
       "22                NaN                NaN                NaN   \n",
       "23                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.946859         0.843157        0.109841                4  \n",
       "1            0.945921         0.853432        0.102649                3  \n",
       "2            0.829684         0.780219        0.162877               10  \n",
       "3            0.807339         0.781185        0.140002                9  \n",
       "4            0.850099         0.774047        0.126599               13  \n",
       "5            0.801709         0.761756        0.197561               16  \n",
       "6            0.938481         0.838072        0.128657                6  \n",
       "7            0.931794         0.839788        0.110743                5  \n",
       "8            0.800279         0.754805        0.221509               18  \n",
       "9            0.794408         0.765871        0.157243               14  \n",
       "10           0.798818         0.765827        0.177479               15  \n",
       "11           0.842442         0.779650        0.160187               11  \n",
       "12           0.945321         0.876363        0.072515                2  \n",
       "13           0.946214         0.883274        0.056272                1  \n",
       "14           0.845097         0.832678        0.105299                7  \n",
       "15           0.808967         0.782810        0.125016                8  \n",
       "16           0.829413         0.775308        0.170293               12  \n",
       "17           0.811095         0.760207        0.198164               17  \n",
       "18                NaN              NaN             NaN               19  \n",
       "19                NaN              NaN             NaN               19  \n",
       "20                NaN              NaN             NaN               19  \n",
       "21                NaN              NaN             NaN               19  \n",
       "22                NaN              NaN             NaN               19  \n",
       "23                NaN              NaN             NaN               19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3966cc5f-fae4-4b10-99b2-e7407633a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_prediction=grid.predict(x_test)\n",
    "#x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ee6e21-7bb3-4884-ae0a-203ec2d64b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428746436758382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r_score=r2_score(y_test,grid_prediction)\n",
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2f01c7-a0a0-4649-b766-8461b320aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"Standard_Scaler.pkl\"\n",
    "pickle.dump(sc,open(filename,'wb'))\n",
    "scx=pickle.load(open('Standard_Scaler.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd8eea39-5016-4768-954d-c50a642550a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"finalized_model_RF_IO.sav\"\n",
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171f19ec-8f58-4654-94d5-e5ac6b739f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.49374843, -4.80327375, -1.53809178,  2.        ,  1.30088727]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput=sc.transform([[22,23.4,0,1,1]])\n",
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6ff855-7353-482e-8bfa-1a7cb9607a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.68452163])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_RF_IO.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6b81ce-e696-4005-99d7-5dcf25e239a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Standard_Scaler_output.pkl\"\n",
    "pickle.dump(scy,open(filename,'wb'))\n",
    "scyy=pickle.load(open('Standard_Scaler_output.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f18e5753-df26-4c89-af59-0f676ff821c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37769.3931]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preoutput=scy.inverse_transform([result])\n",
    "preoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a82ac4-eec5-4930-a8a6-e250cab394fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
