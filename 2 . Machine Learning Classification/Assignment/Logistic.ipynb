{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84a9772-7382-48b0-9bec-86e93e81cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2027cf27-4cfc-4984-87a3-11608ab381fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>c</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>12300.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12400.000000</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>9800.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9200.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.868902</td>\n",
       "      <td>8408.191126</td>\n",
       "      <td>4.705597</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>8500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp sg   al   su     rbc        pc         pcc  \\\n",
       "0     2.000000  76.459948  c  3.0  0.0  normal  abnormal  notpresent   \n",
       "1     3.000000  76.459948  c  2.0  0.0  normal    normal  notpresent   \n",
       "2     4.000000  76.459948  a  1.0  0.0  normal    normal  notpresent   \n",
       "3     5.000000  76.459948  d  1.0  0.0  normal    normal  notpresent   \n",
       "4     5.000000  50.000000  c  0.0  0.0  normal    normal  notpresent   \n",
       "..         ...        ... ..  ...  ...     ...       ...         ...   \n",
       "394  51.492308  70.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "395  51.492308  70.000000  c  0.0  2.0  normal    normal  notpresent   \n",
       "396  51.492308  70.000000  c  3.0  0.0  normal    normal  notpresent   \n",
       "397  51.492308  90.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "398  51.492308  80.000000  a  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba         bgr  ...        pcv            wc        rc  htn   dm  \\\n",
       "0    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "1    notpresent  148.112676  ...  34.000000  12300.000000  4.705597   no   no   \n",
       "2    notpresent   99.000000  ...  34.000000   8408.191126  4.705597   no   no   \n",
       "3    notpresent  148.112676  ...  38.868902   8408.191126  4.705597   no   no   \n",
       "4    notpresent  148.112676  ...  36.000000  12400.000000  4.705597   no   no   \n",
       "..          ...         ...  ...        ...           ...       ...  ...  ...   \n",
       "394  notpresent  219.000000  ...  37.000000   9800.000000  4.400000   no   no   \n",
       "395  notpresent  220.000000  ...  27.000000   8408.191126  4.705597  yes  yes   \n",
       "396  notpresent  110.000000  ...  26.000000   9200.000000  3.400000  yes  yes   \n",
       "397  notpresent  207.000000  ...  38.868902   8408.191126  4.705597  yes  yes   \n",
       "398  notpresent  100.000000  ...  53.000000   8500.000000  4.900000   no   no   \n",
       "\n",
       "     cad  appet    pe  ane classification  \n",
       "0     no    yes   yes   no            yes  \n",
       "1     no    yes  poor   no            yes  \n",
       "2     no    yes  poor   no            yes  \n",
       "3     no    yes  poor  yes            yes  \n",
       "4     no    yes  poor   no            yes  \n",
       "..   ...    ...   ...  ...            ...  \n",
       "394   no    yes  poor   no            yes  \n",
       "395   no    yes  poor  yes            yes  \n",
       "396   no   poor  poor   no            yes  \n",
       "397   no    yes  poor  yes            yes  \n",
       "398   no    yes  poor   no             no  \n",
       "\n",
       "[399 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "dataset=pd.read_csv(\"CKD.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5afe62-06a0-4f5e-8e0a-f04f639bc8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hrmo</th>\n",
       "      <th>...</th>\n",
       "      <th>pc_normal</th>\n",
       "      <th>pcc_present</th>\n",
       "      <th>ba_present</th>\n",
       "      <th>htn_yes</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_yes</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_yes</th>\n",
       "      <th>classification_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>57.482105</td>\n",
       "      <td>3.077356</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>12.518156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>76.459948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.112676</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>51.492308</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age         bp   al   su         bgr          bu        sc  \\\n",
       "0     2.000000  76.459948  3.0  0.0  148.112676   57.482105  3.077356   \n",
       "1     3.000000  76.459948  2.0  0.0  148.112676   22.000000  0.700000   \n",
       "2     4.000000  76.459948  1.0  0.0   99.000000   23.000000  0.600000   \n",
       "3     5.000000  76.459948  1.0  0.0  148.112676   16.000000  0.700000   \n",
       "4     5.000000  50.000000  0.0  0.0  148.112676   25.000000  0.600000   \n",
       "..         ...        ...  ...  ...         ...         ...       ...   \n",
       "394  51.492308  70.000000  0.0  0.0  219.000000   36.000000  1.300000   \n",
       "395  51.492308  70.000000  0.0  2.0  220.000000   68.000000  2.800000   \n",
       "396  51.492308  70.000000  3.0  0.0  110.000000  115.000000  6.000000   \n",
       "397  51.492308  90.000000  0.0  0.0  207.000000   80.000000  6.800000   \n",
       "398  51.492308  80.000000  0.0  0.0  100.000000   49.000000  1.000000   \n",
       "\n",
       "            sod       pot       hrmo  ...  pc_normal  pcc_present  ba_present  \\\n",
       "0    137.528754  4.627244  12.518156  ...          0            0           0   \n",
       "1    137.528754  4.627244  10.700000  ...          1            0           0   \n",
       "2    138.000000  4.400000  12.000000  ...          1            0           0   \n",
       "3    138.000000  3.200000   8.100000  ...          1            0           0   \n",
       "4    137.528754  4.627244  11.800000  ...          1            0           0   \n",
       "..          ...       ...        ...  ...        ...          ...         ...   \n",
       "394  139.000000  3.700000  12.500000  ...          1            0           0   \n",
       "395  137.528754  4.627244   8.700000  ...          1            0           0   \n",
       "396  134.000000  2.700000   9.100000  ...          1            0           0   \n",
       "397  142.000000  5.500000   8.500000  ...          1            0           0   \n",
       "398  140.000000  5.000000  16.300000  ...          1            0           0   \n",
       "\n",
       "     htn_yes  dm_yes  cad_yes  appet_yes  pe_yes  ane_yes  classification_yes  \n",
       "0          0       0        0          1       1        0                   1  \n",
       "1          0       0        0          1       0        0                   1  \n",
       "2          0       0        0          1       0        0                   1  \n",
       "3          0       0        0          1       0        1                   1  \n",
       "4          0       0        0          1       0        0                   1  \n",
       "..       ...     ...      ...        ...     ...      ...                 ...  \n",
       "394        0       0        0          1       0        0                   1  \n",
       "395        1       1        0          1       0        1                   1  \n",
       "396        1       1        0          0       0        0                   1  \n",
       "397        1       1        0          1       0        1                   1  \n",
       "398        0       0        0          1       0        0                   0  \n",
       "\n",
       "[399 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset preprocessing\n",
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6a8f47-8e08-43ec-9b32-e07d54eb5347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_yes\n",
       "1    249\n",
       "0    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"classification_yes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e83a4e-2d12-464e-9a63-7faaef45f93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv',\n",
       "       'wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_yes', 'pe_yes', 'ane_yes', 'classification_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9031977-3c48-4aff-b22c-fe962c0c0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input and coutput columns\n",
    "independent= dataset [['age', 'bp', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hrmo', 'pcv','wc', 'rc', 'sg_b', 'sg_c', 'sg_d', 'sg_e', 'rbc_normal', 'pc_normal',\n",
    "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes','appet_yes', 'pe_yes', 'ane_yes']]\n",
    "dependent = dataset ['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff36e1d-2f6f-4d06-a377-be724d6ea324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(399, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input column size\n",
    "independent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e050e3-ce74-48b5-88f2-e726d420eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aee1fdf-32c7-47e1-ad6e-a288fe3ba765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test set split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(independent,dependent,test_size=1/3,random_state=0)\n",
    "\n",
    "#Standard Scaler -  input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train= sc.fit_transform(x_train)\n",
    "x_test= sc.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d1fdfc4-470b-4361-8a9a-cef4c7964388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "85 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1207, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 90, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.97751924 0.98121084 0.98876    0.97390477 0.98129068\n",
      "        nan        nan        nan 0.96640098        nan 0.97763358\n",
      "        nan 0.97751924 0.98121084 0.98876    0.97390477 0.98129068\n",
      "        nan        nan        nan 0.96640098        nan 0.97763358\n",
      "        nan        nan 0.98121084 0.99255723        nan 0.97763358\n",
      "        nan        nan        nan 0.97014818        nan 0.97763358]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;saga&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'multi_class': ['auto', 'ovr', 'multinomial'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'saga']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Creation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'penalty':['l1','l2','elasticnet',None],'solver':['lbfgs','liblinear','saga'],'multi_class':['auto','ovr','multinomial']}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3,n_jobs=-1,scoring='f1_weighted') \n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(x_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67803f20-4aae-41ae-a25e-b3897de241ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "#print(grid.best_params_) \n",
    "re=grid.cv_results_\n",
    "#print(re)\n",
    "grid_predictions = grid.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4ebc144-97c3-4cbe-ba1d-b9f68394d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.977519</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029047</td>\n",
       "      <td>0.009889</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l1', 'solv...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981211</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006585</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988760</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.973905</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012635</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981291</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': 'elasticnet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': None, 'solv...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.966401</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': None, 'solv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'auto', 'penalty': None, 'solv...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.977634</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.977519</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l1', 'solve...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981211</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988760</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.973905</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.013273</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'l2', 'solve...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981291</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': 'elasticnet'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': None, 'solve...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.944023</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.966401</td>\n",
       "      <td>0.013904</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': None, 'solve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.016516</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'ovr', 'penalty': None, 'solve...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.977634</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l1'...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.981211</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.007883</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.981569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992557</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'l2'...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.977634</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': 'ela...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': None...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.962573</td>\n",
       "      <td>0.970148</td>\n",
       "      <td>0.019082</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': None...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.017660</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'multi_class': 'multinomial', 'penalty': None...</td>\n",
       "      <td>0.963284</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.981217</td>\n",
       "      <td>0.977634</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.000866      0.000818         0.000000        0.000000   \n",
       "1        0.000000      0.000000         0.003050        0.006100   \n",
       "2        0.029047      0.009889         0.003574        0.003646   \n",
       "3        0.006585      0.005433         0.003988        0.003712   \n",
       "4        0.002738      0.000914         0.000986        0.000915   \n",
       "5        0.012635      0.002894         0.000000        0.000000   \n",
       "6        0.001316      0.002631         0.000000        0.000000   \n",
       "7        0.000000      0.000000         0.000000        0.000000   \n",
       "8        0.000653      0.000800         0.000000        0.000000   \n",
       "9        0.002255      0.003175         0.000000        0.000000   \n",
       "10       0.003225      0.006204         0.000000        0.000000   \n",
       "11       0.013974      0.007236         0.000000        0.000000   \n",
       "12       0.000000      0.000000         0.000000        0.000000   \n",
       "13       0.003125      0.006251         0.003125        0.006251   \n",
       "14       0.015932      0.007002         0.003426        0.006232   \n",
       "15       0.004152      0.006072         0.000000        0.000000   \n",
       "16       0.003225      0.006203         0.003719        0.006063   \n",
       "17       0.013273      0.008304         0.003170        0.006340   \n",
       "18       0.000100      0.000200         0.000000        0.000000   \n",
       "19       0.000000      0.000000         0.000000        0.000000   \n",
       "20       0.000000      0.000000         0.000000        0.000000   \n",
       "21       0.006742      0.008282         0.003630        0.006304   \n",
       "22       0.000000      0.000000         0.000000        0.000000   \n",
       "23       0.016516      0.005333         0.002521        0.002708   \n",
       "24       0.000000      0.000000         0.000000        0.000000   \n",
       "25       0.003228      0.006457         0.000000        0.000000   \n",
       "26       0.019459      0.007277         0.003653        0.006077   \n",
       "27       0.007883      0.009843         0.002004        0.003479   \n",
       "28       0.000805      0.001212         0.000000        0.000000   \n",
       "29       0.012513      0.006835         0.004636        0.006226   \n",
       "30       0.000103      0.000205         0.000000        0.000000   \n",
       "31       0.000000      0.000000         0.000000        0.000000   \n",
       "32       0.001347      0.001858         0.000000        0.000000   \n",
       "33       0.007591      0.006856         0.003348        0.006155   \n",
       "34       0.000550      0.000673         0.000000        0.000000   \n",
       "35       0.017660      0.005349         0.002145        0.002969   \n",
       "\n",
       "   param_multi_class param_penalty param_solver  \\\n",
       "0               auto            l1        lbfgs   \n",
       "1               auto            l1    liblinear   \n",
       "2               auto            l1         saga   \n",
       "3               auto            l2        lbfgs   \n",
       "4               auto            l2    liblinear   \n",
       "5               auto            l2         saga   \n",
       "6               auto    elasticnet        lbfgs   \n",
       "7               auto    elasticnet    liblinear   \n",
       "8               auto    elasticnet         saga   \n",
       "9               auto          None        lbfgs   \n",
       "10              auto          None    liblinear   \n",
       "11              auto          None         saga   \n",
       "12               ovr            l1        lbfgs   \n",
       "13               ovr            l1    liblinear   \n",
       "14               ovr            l1         saga   \n",
       "15               ovr            l2        lbfgs   \n",
       "16               ovr            l2    liblinear   \n",
       "17               ovr            l2         saga   \n",
       "18               ovr    elasticnet        lbfgs   \n",
       "19               ovr    elasticnet    liblinear   \n",
       "20               ovr    elasticnet         saga   \n",
       "21               ovr          None        lbfgs   \n",
       "22               ovr          None    liblinear   \n",
       "23               ovr          None         saga   \n",
       "24       multinomial            l1        lbfgs   \n",
       "25       multinomial            l1    liblinear   \n",
       "26       multinomial            l1         saga   \n",
       "27       multinomial            l2        lbfgs   \n",
       "28       multinomial            l2    liblinear   \n",
       "29       multinomial            l2         saga   \n",
       "30       multinomial    elasticnet        lbfgs   \n",
       "31       multinomial    elasticnet    liblinear   \n",
       "32       multinomial    elasticnet         saga   \n",
       "33       multinomial          None        lbfgs   \n",
       "34       multinomial          None    liblinear   \n",
       "35       multinomial          None         saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'multi_class': 'auto', 'penalty': 'l1', 'solv...                NaN   \n",
       "1   {'multi_class': 'auto', 'penalty': 'l1', 'solv...           1.000000   \n",
       "2   {'multi_class': 'auto', 'penalty': 'l1', 'solv...           1.000000   \n",
       "3   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.981569   \n",
       "4   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.963284   \n",
       "5   {'multi_class': 'auto', 'penalty': 'l2', 'solv...           0.981569   \n",
       "6   {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "7   {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "8   {'multi_class': 'auto', 'penalty': 'elasticnet...                NaN   \n",
       "9   {'multi_class': 'auto', 'penalty': None, 'solv...           0.963284   \n",
       "10  {'multi_class': 'auto', 'penalty': None, 'solv...                NaN   \n",
       "11  {'multi_class': 'auto', 'penalty': None, 'solv...           0.963284   \n",
       "12  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...                NaN   \n",
       "13  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...           1.000000   \n",
       "14  {'multi_class': 'ovr', 'penalty': 'l1', 'solve...           1.000000   \n",
       "15  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.981569   \n",
       "16  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.963284   \n",
       "17  {'multi_class': 'ovr', 'penalty': 'l2', 'solve...           0.981569   \n",
       "18  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "19  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "20  {'multi_class': 'ovr', 'penalty': 'elasticnet'...                NaN   \n",
       "21  {'multi_class': 'ovr', 'penalty': None, 'solve...           0.963284   \n",
       "22  {'multi_class': 'ovr', 'penalty': None, 'solve...                NaN   \n",
       "23  {'multi_class': 'ovr', 'penalty': None, 'solve...           0.963284   \n",
       "24  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "25  {'multi_class': 'multinomial', 'penalty': 'l1'...                NaN   \n",
       "26  {'multi_class': 'multinomial', 'penalty': 'l1'...           1.000000   \n",
       "27  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.981569   \n",
       "28  {'multi_class': 'multinomial', 'penalty': 'l2'...                NaN   \n",
       "29  {'multi_class': 'multinomial', 'penalty': 'l2'...           0.963284   \n",
       "30  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "31  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "32  {'multi_class': 'multinomial', 'penalty': 'ela...                NaN   \n",
       "33  {'multi_class': 'multinomial', 'penalty': None...           0.963284   \n",
       "34  {'multi_class': 'multinomial', 'penalty': None...                NaN   \n",
       "35  {'multi_class': 'multinomial', 'penalty': None...           0.963284   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.981233           0.981217           0.962573   \n",
       "2            0.962264           0.981217           1.000000   \n",
       "3            0.981014           0.981217           1.000000   \n",
       "4            0.981233           0.962573           0.981217   \n",
       "5            0.981233           0.981217           0.981217   \n",
       "6                 NaN                NaN                NaN   \n",
       "7                 NaN                NaN                NaN   \n",
       "8                 NaN                NaN                NaN   \n",
       "9            0.962264           0.944023           0.981217   \n",
       "10                NaN                NaN                NaN   \n",
       "11           0.981233           0.981217           0.981217   \n",
       "12                NaN                NaN                NaN   \n",
       "13           0.981233           0.981217           0.962573   \n",
       "14           0.962264           0.981217           1.000000   \n",
       "15           0.981014           0.981217           1.000000   \n",
       "16           0.981233           0.962573           0.981217   \n",
       "17           0.981233           0.981217           0.981217   \n",
       "18                NaN                NaN                NaN   \n",
       "19                NaN                NaN                NaN   \n",
       "20                NaN                NaN                NaN   \n",
       "21           0.962264           0.944023           0.981217   \n",
       "22                NaN                NaN                NaN   \n",
       "23           0.981233           0.981217           0.981217   \n",
       "24                NaN                NaN                NaN   \n",
       "25                NaN                NaN                NaN   \n",
       "26           0.962264           0.981217           1.000000   \n",
       "27           1.000000           0.981217           1.000000   \n",
       "28                NaN                NaN                NaN   \n",
       "29           0.981233           0.981217           0.981217   \n",
       "30                NaN                NaN                NaN   \n",
       "31                NaN                NaN                NaN   \n",
       "32                NaN                NaN                NaN   \n",
       "33           0.981233           1.000000           0.943651   \n",
       "34                NaN                NaN                NaN   \n",
       "35           0.981233           0.981217           0.981217   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 NaN              NaN             NaN               20  \n",
       "1            0.962573         0.977519        0.013997               13  \n",
       "2            0.962573         0.981211        0.016807                6  \n",
       "3            1.000000         0.988760        0.009179                2  \n",
       "4            0.981217         0.973905        0.008965               15  \n",
       "5            0.981217         0.981291        0.000139                4  \n",
       "6                 NaN              NaN             NaN               20  \n",
       "7                 NaN              NaN             NaN               20  \n",
       "8                 NaN              NaN             NaN               20  \n",
       "9            0.981217         0.966401        0.013904               18  \n",
       "10                NaN              NaN             NaN               20  \n",
       "11           0.981217         0.977634        0.007175                9  \n",
       "12                NaN              NaN             NaN               20  \n",
       "13           0.962573         0.977519        0.013997               13  \n",
       "14           0.962573         0.981211        0.016807                6  \n",
       "15           1.000000         0.988760        0.009179                2  \n",
       "16           0.981217         0.973905        0.008965               15  \n",
       "17           0.981217         0.981291        0.000139                4  \n",
       "18                NaN              NaN             NaN               20  \n",
       "19                NaN              NaN             NaN               20  \n",
       "20                NaN              NaN             NaN               20  \n",
       "21           0.981217         0.966401        0.013904               18  \n",
       "22                NaN              NaN             NaN               20  \n",
       "23           0.981217         0.977634        0.007175                9  \n",
       "24                NaN              NaN             NaN               20  \n",
       "25                NaN              NaN             NaN               20  \n",
       "26           0.962573         0.981211        0.016807                6  \n",
       "27           1.000000         0.992557        0.009116                1  \n",
       "28                NaN              NaN             NaN               20  \n",
       "29           0.981217         0.977634        0.007175                9  \n",
       "30                NaN              NaN             NaN               20  \n",
       "31                NaN              NaN             NaN               20  \n",
       "32                NaN              NaN             NaN               20  \n",
       "33           0.962573         0.970148        0.019082               17  \n",
       "34                NaN              NaN             NaN               20  \n",
       "35           0.981217         0.977634        0.007175                9  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "table=pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9433520c-b3ec-4e4b-a536-824c97a8dadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion Matrix:\n",
      " [[51  0]\n",
      " [ 1 81]]\n"
     ]
    }
   ],
   "source": [
    "# here going to use confusion matrix instead of R2_Score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix (y_test,grid_predictions)\n",
    "print(\"The confusion Matrix:\\n\",cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8981564-255c-47e2-bcb0-65ba5e03285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        51\n",
      "           1       1.00      0.99      0.99        82\n",
      "\n",
      "    accuracy                           0.99       133\n",
      "   macro avg       0.99      0.99      0.99       133\n",
      "weighted avg       0.99      0.99      0.99       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report to find recall, f1_score, precision, support\n",
    "from sklearn.metrics import classification_report\n",
    "clf_report =classification_report(y_test,grid_predictions)\n",
    "print(\"The report:\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9892f917-3a0d-4c21-ae29-e66c34600de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_macro value for best parameter {'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}: 0.9924946382275899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_macro=f1_score(y_test,grid_predictions,average='weighted')\n",
    "print(\"The f1_macro value for best parameter {}:\".format(grid.best_params_),f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63205afd-0e69-43bd-80ac-689ddc360bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_input=float(input(\"Age:\"))\n",
    "#salary_input=float(input(\"BMI:\"))\n",
    "#sex_male_input=int(input(\"Sex Male 0 or 1:\"))\n",
    "#classifier.predict([[age_input,salary_input,sex_male_input]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49fd4d9b-8a23-40b3-abe2-e9d6fd2c5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"Standard_Scaler_Classi_Logistic_Input.pkl\"\n",
    "pickle.dump(sc,open(filename,'wb'))\n",
    "scx=pickle.load(open('Standard_Scaler_Classi_Logistic_Input.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da586864-52f2-4a47-bc80-4715714699bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"finalized_model_Logistic_Classification.sav\"\n",
    "pickle.dump(grid,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "347a7f02-f672-4889-b40b-cd4ee101431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santhiya\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.04452180e+00, -4.68876811e-02,  4.31675741e+01,\n",
       "         9.85032393e+01, -9.64824402e-01, -1.16253954e-01,\n",
       "         8.55517394e+00, -1.19331973e+01,  2.08206603e+02,\n",
       "         3.16306070e+01, -1.84633947e+00, -3.45706306e+00,\n",
       "         3.59258840e+01,  1.33150900e+02,  1.32661744e+02,\n",
       "         1.78260893e+02,  3.16486324e+02,  2.99722094e+01,\n",
       "         2.27334952e+01,  2.91547595e+00, -2.35702260e-01,\n",
       "         1.35269628e+00, -7.39264248e-01,  3.41565026e+00,\n",
       "        -1.93649167e+00,  1.91485422e+00, -4.45194562e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput=sc.transform([[35, 76, 54, 98, 76.00, 54, 54, 11.9, 467.9, 98.00, 24,18.9, 34, 53, 56, 67, 43, 11, 10,1, 0, 1, 0, 1,0, 1, 0]])\n",
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43f05b0-599c-45a7-a225-2db29676871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_Logistic_Classification.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9f0a0-204b-44bf-acac-3dea67cefdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42025b18-1ac8-428a-97fe-f71b9ccac639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
